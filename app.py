import streamlit as st
import sqlite3
import os
import uuid
import json
from datetime import datetime
import pandas as pd


PRIMARY_COLOR = "#007AFF"
st.set_page_config(page_title="ClarityOS", layout="wide")

st.markdown(
    f"""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
    html, body, [class*="css"]  {{
        font-family: 'Inter', sans-serif;
    }}
    .stButton>button {{
        background:{PRIMARY_COLOR};
        color:white;
        border-radius:8px;
        border:none;
    }}
    .metric-card {{
        background:white;
        border:1px solid rgba(0,0,0,0.03);
        border-radius:16px;
        padding:14px 16px 6px 16px;
        box-shadow:0 10px 25px rgba(0,0,0,0.02);
    }}
    .insight {{
        background:rgba(0,122,255,0.07);
        border-left:4px solid {PRIMARY_COLOR};
        padding:10px 12px;
        border-radius:6px;
        margin-bottom:8px;
    }}
    </style>
    """,
    unsafe_allow_html=True,
)

DB_PATH = "clarityos.db"


@st.cache_resource
def get_conn() -> sqlite3.Connection:
    # –æ–¥–∏–Ω-–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–Ω–Ω–µ–∫—Ç –Ω–∞ –≤—Å—ë –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.execute("PRAGMA foreign_keys = ON;")
    return conn


@st.cache_resource
def init_db() -> None:
    conn = get_conn()
    c = conn.cursor()

    # —Ä–∞–±–æ—á–∏–µ –æ–±–ª–∞—Å—Ç–∏
    c.execute("""
    CREATE TABLE IF NOT EXISTS workspace (
        id TEXT PRIMARY KEY,
        name TEXT NOT NULL,
        created_at TEXT NOT NULL
    );
    """)

    # –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    c.execute("""
    CREATE TABLE IF NOT EXISTS data_source (
        id TEXT PRIMARY KEY,
        workspace_id TEXT NOT NULL,
        type TEXT NOT NULL,
        title TEXT,
        source_url TEXT,
        status TEXT,
        category TEXT,              -- 'orders' | 'expenses'
        created_at TEXT NOT NULL,
        updated_at TEXT,
        FOREIGN KEY (workspace_id) REFERENCES workspace (id) ON DELETE CASCADE
    );
    """)

    # —Ñ–∞–∫—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏
    c.execute("""
    CREATE TABLE IF NOT EXISTS data_upload (
        id TEXT PRIMARY KEY,
        data_source_id TEXT NOT NULL,
        original_filename TEXT,
        storage_path TEXT,
        detected_schema TEXT,
        rows_count INTEGER,
        created_at TEXT NOT NULL,
        FOREIGN KEY (data_source_id) REFERENCES data_source (id) ON DELETE CASCADE
    );
    """)

    # –∑–∞–∫–∞–∑—ã
    c.execute("""
    CREATE TABLE IF NOT EXISTS "order" (
        id TEXT PRIMARY KEY,
        data_source_id TEXT NOT NULL,
        external_id TEXT,
        order_date TEXT,
        customer_name TEXT,
        product TEXT,
        revenue REAL,
        channel TEXT,
        created_at TEXT NOT NULL,
        FOREIGN KEY (data_source_id) REFERENCES data_source (id) ON DELETE CASCADE
    );
    """)

    # —Ä–∞—Å—Ö–æ–¥—ã
    c.execute("""
    CREATE TABLE IF NOT EXISTS expense (
        id TEXT PRIMARY KEY,
        data_source_id TEXT NOT NULL,
        expense_date TEXT,
        category TEXT,
        amount REAL,
        created_at TEXT NOT NULL,
        FOREIGN KEY (data_source_id) REFERENCES data_source (id) ON DELETE CASCADE
    );
    """)

    # –∫–ª–∏–µ–Ω—Ç—ã
    c.execute("""
    CREATE TABLE IF NOT EXISTS customer (
        id TEXT PRIMARY KEY,
        workspace_id TEXT NOT NULL,
        name TEXT NOT NULL,
        created_at TEXT NOT NULL,
        FOREIGN KEY (workspace_id) REFERENCES workspace (id) ON DELETE CASCADE
    );
    """)

    # —Å–Ω–∞–ø—à–æ—Ç—ã
    c.execute("""
    CREATE TABLE IF NOT EXISTS metrics_snapshot (
        id TEXT PRIMARY KEY,
        workspace_id TEXT NOT NULL,
        period_from TEXT,
        period_to TEXT,
        payload_json TEXT,
        created_at TEXT NOT NULL,
        FOREIGN KEY (workspace_id) REFERENCES workspace (id) ON DELETE CASCADE
    );
    """)

    # –∏–Ω—Å–∞–π—Ç—ã
    c.execute("""
    CREATE TABLE IF NOT EXISTS insight (
        id TEXT PRIMARY KEY,
        workspace_id TEXT NOT NULL,
        metrics_snapshot_id TEXT,
        text TEXT,
        rule_code TEXT,
        created_at TEXT NOT NULL,
        FOREIGN KEY (workspace_id) REFERENCES workspace (id) ON DELETE CASCADE
    );
    """)

    conn.commit()


# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
init_db()


    # core tables
    c.execute("""
    CREATE TABLE IF NOT EXISTS user (
        id TEXT PRIMARY KEY,
        email TEXT,
        name TEXT,
        created_at TEXT
    )""")

    c.execute("""
    CREATE TABLE IF NOT EXISTS workspace (
        id TEXT PRIMARY KEY,
        owner_id TEXT,
        name TEXT,
        created_at TEXT
    )""")

    # data_source –±–µ–∑ category
    c.execute("""
    CREATE TABLE IF NOT EXISTS data_source (
        id TEXT PRIMARY KEY,
        workspace_id TEXT,
        type TEXT,
        title TEXT,
        source_url TEXT,
        status TEXT,
        created_at TEXT,
        updated_at TEXT
    )""")

    # –º–∏–≥—Ä–∞—Ü–∏—è: category
    c.execute("PRAGMA table_info(data_source)")
    cols = [r[1] for r in c.fetchall()]
    if "category" not in cols:
        c.execute("ALTER TABLE data_source ADD COLUMN category TEXT DEFAULT NULL")

    c.execute("""
    CREATE TABLE IF NOT EXISTS data_upload (
        id TEXT PRIMARY KEY,
        data_source_id TEXT,
        original_filename TEXT,
        storage_path TEXT,
        detected_schema TEXT,
        rows_count INTEGER,
        created_at TEXT
    )""")

    c.execute("""
    CREATE TABLE IF NOT EXISTS mapping_profile (
        id TEXT PRIMARY KEY,
        data_source_id TEXT,
        target_table TEXT,
        mapping_json TEXT,
        status TEXT,
        created_at TEXT
    )""")

    c.execute("""
    CREATE TABLE IF NOT EXISTS "order" (
        id TEXT PRIMARY KEY,
        data_source_id TEXT,
        external_id TEXT,
        order_date TEXT,
        customer_name TEXT,
        product TEXT,
        revenue REAL,
        channel TEXT,
        customer_id TEXT,
        created_at TEXT
    )""")

    c.execute("""
    CREATE TABLE IF NOT EXISTS expense (
        id TEXT PRIMARY KEY,
        data_source_id TEXT,
        expense_date TEXT,
        category TEXT,
        amount REAL,
        created_at TEXT
    )""")

    c.execute("""
    CREATE TABLE IF NOT EXISTS customer (
        id TEXT PRIMARY KEY,
        workspace_id TEXT,
        name TEXT,
        created_at TEXT
    )""")

    c.execute("""
    CREATE TABLE IF NOT EXISTS metrics_snapshot (
        id TEXT PRIMARY KEY,
        workspace_id TEXT,
        period_from TEXT,
        period_to TEXT,
        payload_json TEXT,
        created_at TEXT
    )""")

    c.execute("""
    CREATE TABLE IF NOT EXISTS insight (
        id TEXT PRIMARY KEY,
        workspace_id TEXT,
        metrics_snapshot_id TEXT,
        text TEXT,
        rule_code TEXT,
        created_at TEXT
    )""")

    # demo user/workspace
    c.execute("SELECT COUNT(*) FROM user")
    if c.fetchone()[0] == 0:
        user_id = str(uuid.uuid4())
        ws_id = str(uuid.uuid4())
        now = datetime.utcnow().isoformat()
        c.execute("INSERT INTO user (id, email, name, created_at) VALUES (?,?,?,?)",
                  (user_id, "demo@clarityos.app", "Demo User", now))
        c.execute("INSERT INTO workspace (id, owner_id, name, created_at) VALUES (?,?,?,?)",
                  (ws_id, user_id, "Demo workspace", now))
    conn.commit()
    conn.close()

init_db()

# ------------------ helpers ------------------
def list_workspaces():
    conn = get_conn()
    c = conn.cursor()
    c.execute("SELECT id, name FROM workspace ORDER BY created_at DESC")
    rows = c.fetchall()
    conn.close()
    return rows

def create_workspace(name: str):
    conn = get_conn()
    c = conn.cursor()
    c.execute("SELECT id FROM user LIMIT 1")
    owner_id = c.fetchone()[0]
    ws_id = str(uuid.uuid4())
    now = datetime.utcnow().isoformat()
    c.execute("INSERT INTO workspace (id, owner_id, name, created_at) VALUES (?,?,?,?)",
              (ws_id, owner_id, name, now))
    conn.commit()
    conn.close()
    return ws_id

def parse_google_sheet_to_csv_url(url: str):
    if "docs.google.com/spreadsheets" not in url:
        return None
    parsed = urlparse(url)
    parts = parsed.path.split("/")
    sheet_id = parts[3]
    qs = parse_qs(parsed.fragment)
    gid = qs.get("gid", ["0"])[0]
    return f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"

def suggest_mapping(detected_cols):
    orders_targets = [
        {"target":"order_id","label":"ID –∑–∞–∫–∞–∑–∞","required":True,"synonyms":["id","order","orderno","–Ω–æ–º–µ—Ä","id –∑–∞–∫–∞–∑–∞"]},
        {"target":"order_date","label":"–î–∞—Ç–∞ –∑–∞–∫–∞–∑–∞","required":True,"synonyms":["date","order_date","–¥–∞—Ç–∞"]},
        {"target":"customer_name","label":"–ö–ª–∏–µ–Ω—Ç","required":True,"synonyms":["client","customer","–∫–ª–∏–µ–Ω—Ç","name"]},
        {"target":"product","label":"–ü—Ä–æ–¥—É–∫—Ç","required":True,"synonyms":["product","—Ç–æ–≤–∞—Ä","course","–ø–æ–∑–∏—Ü–∏—è"]},
        {"target":"revenue","label":"–í—ã—Ä—É—á–∫–∞","required":True,"synonyms":["revenue","amount","sum","–¥–æ—Ö–æ–¥","–≤—ã—Ä—É—á–∫–∞","price"]},
        {"target":"channel","label":"–ö–∞–Ω–∞–ª","required":False,"synonyms":["utm_source","channel","–∫–∞–Ω–∞–ª"]},
    ]
    expenses_targets = [
        {"target":"expense_date","label":"–î–∞—Ç–∞ —Ä–∞—Å—Ö–æ–¥–∞","required":True,"synonyms":["date","–¥–∞—Ç–∞"]},
        {"target":"category","label":"–ö–∞—Ç–µ–≥–æ—Ä–∏—è","required":True,"synonyms":["category","–∫–∞—Ç–µ–≥–æ—Ä–∏—è","type"]},
        {"target":"amount","label":"–°—É–º–º–∞","required":True,"synonyms":["amount","sum","—Å—É–º–º–∞","cost","—Ä–∞—Å—Ö–æ–¥"]},
    ]

    def find_suggest(syns):
        for col in detected_cols:
            cl = col.lower().strip()
            for s in syns:
                if s in cl:
                    return col
        return None

    for t in orders_targets:
        t["suggested_column"] = find_suggest(t["synonyms"])
    for t in expenses_targets:
        t["suggested_column"] = find_suggest(t["synonyms"])

    return {"orders": orders_targets, "expenses": expenses_targets}

def apply_mapping_to_df(df: pd.DataFrame, mapping: dict, target_table: str):
    out = {}
    for target, source in mapping.items():
        if source and source in df.columns:
            out[target] = df[source]
        else:
            out[target] = None
    out_df = pd.DataFrame(out)

    if target_table == "orders":
        req = ["order_id","order_date","customer_name","product","revenue"]
        for col in req:
            if col not in out_df.columns:
                raise ValueError(f"{col} is required")
        out_df["order_date"] = pd.to_datetime(out_df["order_date"], errors="coerce")
        out_df = out_df[out_df["order_date"].notna()]
        out_df["revenue"] = (
            out_df["revenue"].astype(str).str.replace(" ", "", regex=False).str.replace(",", ".", regex=False)
        )
        out_df["revenue"] = pd.to_numeric(out_df["revenue"], errors="coerce").fillna(0.0)
    else:
        req = ["expense_date","category","amount"]
        for col in req:
            if col not in out_df.columns:
                raise ValueError(f"{col} is required")
        out_df["expense_date"] = pd.to_datetime(out_df["expense_date"], errors="coerce")
        out_df = out_df[out_df["expense_date"].notna()]
        out_df["amount"] = (
            out_df["amount"].astype(str).str.replace(" ", "", regex=False).str.replace(",", ".", regex=False)
        )
        out_df["amount"] = pd.to_numeric(out_df["amount"], errors="coerce").fillna(0.0)
    return out_df

def insert_orders(df: pd.DataFrame, ds_id: str):
    conn = get_conn()
    c = conn.cursor()
    now = datetime.utcnow().isoformat()
    for _, row in df.iterrows():
        c.execute(
            """INSERT INTO "order"
            (id, data_source_id, external_id, order_date, customer_name, product, revenue, channel, customer_id, created_at)
            VALUES (?,?,?,?,?,?,?,?,?,?)""",
            (
                str(uuid.uuid4()),
                ds_id,
                str(row["order_id"]),
                row["order_date"].date().isoformat(),
                str(row["customer_name"]),
                str(row["product"]),
                float(row["revenue"]),
                str(row.get("channel") if pd.notna(row.get("channel")) else None),
                None,
                now,
            ),
        )
    conn.commit()
    conn.close()

def insert_expenses(df: pd.DataFrame, ds_id: str):
    conn = get_conn()
    c = conn.cursor()
    now = datetime.utcnow().isoformat()
    for _, row in df.iterrows():
        c.execute(
            """INSERT INTO expense
            (id, data_source_id, expense_date, category, amount, created_at)
            VALUES (?,?,?,?,?,?)""",
            (
                str(uuid.uuid4()),
                ds_id,
                row["expense_date"].date().isoformat(),
                str(row["category"]),
                float(row["amount"]),
                now,
            ),
        )
    conn.commit()
    conn.close()

def rebuild_customers(ws_id: str):
    conn = get_conn()
    c = conn.cursor()
    c.execute("""
        SELECT DISTINCT o.customer_name
        FROM "order" o
        JOIN data_source ds ON ds.id = o.data_source_id
        WHERE ds.workspace_id = ?
    """, (ws_id,))
    names = [r[0] for r in c.fetchall() if r[0]]
    c.execute("SELECT name FROM customer WHERE workspace_id = ?", (ws_id,))
    existing = {r[0] for r in c.fetchall()}
    now = datetime.utcnow().isoformat()
    for name in names:
        if name not in existing:
            c.execute("INSERT INTO customer (id, workspace_id, name, created_at) VALUES (?,?,?,?)",
                      (str(uuid.uuid4()), ws_id, name, now))
    conn.commit()
    conn.close()

def calc_metrics(ws_id: str):
    conn = get_conn()
    c = conn.cursor()
    c.execute("""
        SELECT o.order_date, o.revenue
        FROM "order" o
        JOIN data_source ds ON ds.id = o.data_source_id
        WHERE ds.workspace_id = ?
    """, (ws_id,))
    orders_df = pd.DataFrame(c.fetchall(), columns=["order_date","revenue"])
    if not orders_df.empty:
        orders_df["order_date"] = pd.to_datetime(orders_df["order_date"])

    c.execute("""
        SELECT e.expense_date, e.amount
        FROM expense e
        JOIN data_source ds ON ds.id = e.data_source_id
        WHERE ds.workspace_id = ?
    """, (ws_id,))
    exp_df = pd.DataFrame(c.fetchall(), columns=["expense_date","amount"])
    if not exp_df.empty:
        exp_df["expense_date"] = pd.to_datetime(exp_df["expense_date"])

    revenue = float(orders_df["revenue"].sum()) if not orders_df.empty else 0.0
    expenses = float(exp_df["amount"].sum()) if not exp_df.empty else 0.0
    profit = revenue - expenses
    margin = profit / revenue if revenue > 0 else None

    # avg check
    c.execute("""
        SELECT COUNT(DISTINCT o.external_id)
        FROM "order" o
        JOIN data_source ds ON ds.id = o.data_source_id
        WHERE ds.workspace_id = ?
    """, (ws_id,))
    distinct_orders = c.fetchone()[0]
    avg_check = (revenue / distinct_orders) if distinct_orders else None

    revenue_series = []
    if not orders_df.empty:
        s = orders_df.groupby(orders_df["order_date"].dt.to_period("M"))["revenue"].sum().reset_index()
        for _, r in s.iterrows():
            revenue_series.append({"period": str(r["order_date"]), "revenue": float(r["revenue"])})

    expenses_series = []
    if not exp_df.empty:
        s = exp_df.groupby(exp_df["expense_date"].dt.to_period("M"))["amount"].sum().reset_index()
        for _, r in s.iterrows():
            expenses_series.append({"period": str(r["expense_date"]), "expenses": float(r["amount"])})

    # top customers
    c.execute("""
        SELECT o.customer_name, SUM(o.revenue) as rev, COUNT(*) as cnt, MAX(o.order_date)
        FROM "order" o
        JOIN data_source ds ON ds.id = o.data_source_id
        WHERE ds.workspace_id = ?
        GROUP BY o.customer_name
        ORDER BY rev DESC
        LIMIT 20
    """, (ws_id,))
    tops = []
    for row in c.fetchall():
        tops.append({
            "customer_name": row[0],
            "revenue": float(row[1]),
            "orders": int(row[2]),
            "ltv": float(row[1]),
            "last_order_date": row[3]
        })

    top_share = 0.0
    if revenue > 0 and tops:
        top_5 = sum(t["revenue"] for t in tops[:5])
        top_share = top_5 / revenue

    conn.close()

    return {
        "revenue": revenue,
        "expenses": expenses,
        "profit": profit,
        "margin": margin,
        "avg_check": avg_check,
        "revenue_series": revenue_series,
        "expenses_series": expenses_series,
        "top_customers": tops,
        "top_customers_share": top_share,
        "period": {"from": None, "to": None},
    }

def growth(series_list, key):
    if not series_list or len(series_list) < 2:
        return 0.0
    first = series_list[-2].get(key, 0)
    last = series_list[-1].get(key, 0)
    if first == 0:
        return 0.0
    return (last - first) / first

def generate_insights(m):
    ins = []
    rev_g = growth(m["revenue_series"], "revenue")
    exp_g = growth(m["expenses_series"], "expenses")
    if rev_g < 0 and exp_g > 0:
        ins.append("–ü—Ä–∏–±—ã–ª—å —Å–Ω–∏–∑–∏–ª–∞—Å—å –∏–∑-–∑–∞ —Ä–æ—Å—Ç–∞ —Ä–∞—Å—Ö–æ–¥–æ–≤ –ø—Ä–∏ –ø–∞–¥–µ–Ω–∏–∏ –≤—ã—Ä—É—á–∫–∏.")
    if m["top_customers_share"] > 0.6:
        ins.append("70% –≤—ã—Ä—É—á–∫–∏ –¥–∞–µ—Ç —É–∑–∫–∞—è –≥—Ä—É–ø–ø–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ ‚Äî –¥–µ—Ä–∂–∏—Ç–µ –∏—Ö –≤ —Ñ–æ–∫—É—Å–µ.")
    if exp_g > 0.3:
        ins.append("–†–∞—Å—Ö–æ–¥—ã —Ä–∞—Å—Ç—É—Ç –±—ã—Å—Ç—Ä–µ–µ –≤—ã—Ä—É—á–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏.")
    if not ins:
        ins.append("–ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã, –∑–Ω–∞—á–∏–º—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π –Ω–µ—Ç.")
    return ins[:3]

# ----------------- SIDEBAR: workspaces only -----------------
st.sidebar.title("–†–∞–±–æ—á–∏–µ –æ–±–ª–∞—Å—Ç–∏")
workspaces = list_workspaces()
ws_names = {ws_id: name for ws_id, name in workspaces}

if "current_ws" not in st.session_state:
    st.session_state.current_ws = workspaces[0][0] if workspaces else None

selected_ws_name = st.sidebar.selectbox(
    "–í—ã–±–µ—Ä–∏ –æ–±–ª–∞—Å—Ç—å",
    options=[ws_names[w[0]] for w in workspaces] if workspaces else [],
    index=0 if workspaces else None,
)
for ws_id, name in ws_names.items():
    if name == selected_ws_name:
        st.session_state.current_ws = ws_id
        break

with st.sidebar.expander("‚ûï –ù–æ–≤–∞—è –æ–±–ª–∞—Å—Ç—å"):
    new_ws = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏")
    if st.button("–°–æ–∑–¥–∞—Ç—å –æ–±–ª–∞—Å—Ç—å"):
        if new_ws.strip():
            ws_id = create_workspace(new_ws.strip())
            st.session_state.current_ws = ws_id
            st.rerun()

current_ws = st.session_state.current_ws

# ----------------- session for uploads (split) -----------------
# –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –æ–ø–ª–∞—Ç –∏ –¥–ª—è —Ä–∞—Å—Ö–æ–¥–æ–≤
for key in [
    "orders_df", "orders_ds_id", "orders_schema",
    "expenses_df", "expenses_ds_id", "expenses_schema",
]:
    if key not in st.session_state:
        st.session_state[key] = None

# ----------------- MAIN TABS -----------------
st.title(f"ClarityOS ‚Äî {ws_names.get(current_ws, '')}")
tab_dashboard, tab_upload, tab_mapping = st.tabs(["–î–∞—à–±–æ—Ä–¥", "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", "–ú–∞–ø–ø–∏–Ω–≥"])

# ======== DASHBOARD ========
with tab_dashboard:
    st.subheader("–î–∞—à–±–æ—Ä–¥")

    # 0. –µ—Å–ª–∏ –æ–±–ª–∞—Å—Ç—å –Ω–µ –≤—ã–±—Ä–∞–Ω–∞
    if not current_ws:
        st.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–±–æ—á—É—é –æ–±–ª–∞—Å—Ç—å –≤ —Å–∞–π–¥–±–∞—Ä–µ.")
        st.stop()

    conn = get_conn()
    c = conn.cursor()

    # 1. –≤—ã—Ä—É—á–∫–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–ª–∞—Ç
    c.execute("""
        SELECT COUNT(*), COALESCE(SUM(revenue), 0)
        FROM "order" o
        JOIN data_source ds ON ds.id = o.data_source_id
        WHERE ds.workspace_id = ?
    """, (current_ws,))
    orders_cnt, orders_sum = c.fetchone()

    # 2. —Ä–∞—Å—Ö–æ–¥—ã
    c.execute("""
        SELECT COUNT(*), COALESCE(SUM(amount), 0)
        FROM expense e
        JOIN data_source ds ON ds.id = e.data_source_id
        WHERE ds.workspace_id = ?
    """, (current_ws,))
    exp_cnt, exp_sum = c.fetchone()

    # 3. —Ç–æ–ø –∫–ª–∏–µ–Ω—Ç–æ–≤ (–ø—Ä–æ—Å—Ç–æ –ø–æ –∏–º–µ–Ω–∏)
    c.execute("""
        SELECT o.customer_name, COALESCE(SUM(o.revenue),0) AS rev, COUNT(*) AS cnt
        FROM "order" o
        JOIN data_source ds ON ds.id = o.data_source_id
        WHERE ds.workspace_id = ?
        GROUP BY o.customer_name
        ORDER BY rev DESC
        LIMIT 20
    """, (current_ws,))
    top_customers = c.fetchall()

    # 4. –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ ‚Äî —á—Ç–æ–±—ã –ø—Ä–æ—Å—Ç–æ —É–≤–∏–¥–µ—Ç—å
    c.execute("""
        SELECT o.external_id, o.order_date, o.customer_name, o.product, o.revenue
        FROM "order" o
        JOIN data_source ds ON ds.id = o.data_source_id
        WHERE ds.workspace_id = ?
        ORDER BY o.created_at DESC
        LIMIT 10
    """, (current_ws,))
    last_orders = c.fetchall()

    c.execute("""
        SELECT e.expense_date, e.category, e.amount
        FROM expense e
        JOIN data_source ds ON ds.id = e.data_source_id
        WHERE ds.workspace_id = ?
        ORDER BY e.created_at DESC
        LIMIT 10
    """, (current_ws,))
    last_exp = c.fetchall()

    conn.close()

    # --- DIAG ---
    st.caption(
        f"üîé –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –æ–ø–ª–∞—Ç {orders_cnt}, –≤—ã—Ä—É—á–∫–∞ {orders_sum}; "
        f"—Ä–∞—Å—Ö–æ–¥–æ–≤ {exp_cnt}, —Å—É–º–º–∞ {exp_sum}"
    )

    # –µ—Å–ª–∏ –∏ —Ç—É—Ç 0 ‚Äî –∑–Ω–∞—á–∏—Ç –¥–∞–Ω–Ω—ã–µ –≤–æ–æ–±—â–µ –Ω–µ –¥–æ–ª–µ—Ç–µ–ª–∏
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("–í—ã—Ä—É—á–∫–∞", f"{orders_sum:,.0f} ‚ÇΩ".replace(",", " "))
    col2.metric("–†–∞—Å—Ö–æ–¥—ã", f"{exp_sum:,.0f} ‚ÇΩ".replace(",", " "))
    profit = orders_sum - exp_sum
    col3.metric("–ü—Ä–∏–±—ã–ª—å", f"{profit:,.0f} ‚ÇΩ".replace(",", " "))
    margin = (profit / orders_sum) if orders_sum else 0
    col4.metric("–ú–∞—Ä–∂–∞", f"{margin*100:,.1f} %" if orders_sum else "‚Äî")

    st.markdown("#### –¢–æ–ø –∫–ª–∏–µ–Ω—Ç–æ–≤")
    if top_customers:
        st.dataframe(
            [
                {
                    "–ö–ª–∏–µ–Ω—Ç": row[0],
                    "–í—ã—Ä—É—á–∫–∞": row[1],
                    "–ö–æ–ª-–≤–æ –∑–∞–∫–∞–∑–æ–≤": row[2],
                }
                for row in top_customers
            ]
        )
    else:
        st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º.")

    st.markdown("#### –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –æ–ø–ª–∞—Ç")
    if last_orders:
        st.dataframe(
            [
                {
                    "ID": row[0],
                    "–î–∞—Ç–∞": row[1],
                    "–ö–ª–∏–µ–Ω—Ç": row[2],
                    "–ü—Ä–æ–¥—É–∫—Ç": row[3],
                    "–°—É–º–º–∞": row[4],
                }
                for row in last_orders
            ]
        )
    else:
        st.write("–ü–æ–∫–∞ –Ω–µ—Ç –æ–ø–ª–∞—Ç –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏.")

    st.markdown("#### –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Ä–∞—Å—Ö–æ–¥–æ–≤")
    if last_exp:
        st.dataframe(
            [
                {
                    "–î–∞—Ç–∞": row[0],
                    "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": row[1],
                    "–°—É–º–º–∞": row[2],
                }
                for row in last_exp
            ]
        )
    else:
        st.write("–ü–æ–∫–∞ –Ω–µ—Ç —Ä–∞—Å—Ö–æ–¥–æ–≤ –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏.")


# ======== UPLOAD ========
with tab_upload:
    st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    left, right = st.columns(2)

    # ---- LEFT: orders ----
    with left:
        st.markdown("### –û–ø–ª–∞—Ç—ã (orders)")
        orders_file = st.file_uploader("CSV —Å –æ–ø–ª–∞—Ç–∞–º–∏", type=["csv"], key="orders_upload")
        orders_gsheet = st.text_input("Google Sheets —Å –æ–ø–ª–∞—Ç–∞–º–∏ (–ø—É–±–ª–∏—á–Ω—ã–π)", key="orders_gsheet")

        if orders_file is not None:
            content = orders_file.read()
            try:
                df = pd.read_csv(io.BytesIO(content), sep=";")
                if df.shape[1] == 1:
                    df = pd.read_csv(io.BytesIO(content), sep=",")
            except Exception:
                df = pd.read_csv(io.BytesIO(content), sep=",")
            detected = list(df.columns)

            conn = get_conn()
            c = conn.cursor()
            ds_id = str(uuid.uuid4())
            now = datetime.utcnow().isoformat()
            c.execute("""INSERT INTO data_source
                (id, workspace_id, type, title, source_url, status, category, created_at, updated_at)
                VALUES (?,?,?,?,?,?,?,?,?)""",
                (ds_id, current_ws, "csv", orders_file.name, None, "uploaded", "orders", now, now))
            up_id = str(uuid.uuid4())
            c.execute("""INSERT INTO data_upload
                (id, data_source_id, original_filename, storage_path, detected_schema, rows_count, created_at)
                VALUES (?,?,?,?,?,?,?)""",
                (up_id, ds_id, orders_file.name, "", ",".join(detected), len(df), now))
            conn.commit()
            conn.close()

            st.session_state.orders_df = df
            st.session_state.orders_ds_id = ds_id
            st.session_state.orders_schema = detected

            st.success("–û–ø–ª–∞—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É ¬´–ú–∞–ø–ø–∏–Ω–≥¬ª ‚Üí –ª–µ–≤—ã–π –±–ª–æ–∫.")
            st.dataframe(df.head())

        elif orders_gsheet:
            csv_url = parse_google_sheet_to_csv_url(orders_gsheet)
            if not csv_url:
                st.error("–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ Google Sheets")
            else:
                df = pd.read_csv(csv_url)
                detected = list(df.columns)

                conn = get_conn()
                c = conn.cursor()
                ds_id = str(uuid.uuid4())
                now = datetime.utcnow().isoformat()
                c.execute("""INSERT INTO data_source
                    (id, workspace_id, type, title, source_url, status, category, created_at, updated_at)
                    VALUES (?,?,?,?,?,?,?,?,?)""",
                    (ds_id, current_ws, "google_sheets", "Google Sheet (orders)", orders_gsheet, "uploaded", "orders", now, now))
                up_id = str(uuid.uuid4())
                c.execute("""INSERT INTO data_upload
                    (id, data_source_id, original_filename, storage_path, detected_schema, rows_count, created_at)
                    VALUES (?,?,?,?,?,?,?)""",
                    (up_id, ds_id, "sheet_orders", "", ",".join(detected), len(df), now))
                conn.commit()
                conn.close()

                st.session_state.orders_df = df
                st.session_state.orders_ds_id = ds_id
                st.session_state.orders_schema = detected

                st.success("–û–ø–ª–∞—Ç—ã –∏–∑ Google Sheets –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
                st.dataframe(df.head())

        # —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö sources (orders)
        st.markdown("#### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –æ–ø–ª–∞—Ç")
        conn = get_conn()
        c = conn.cursor()
        c.execute("""
            SELECT id, title, type, status, created_at
            FROM data_source
            WHERE workspace_id = ? AND category = 'orders'
            ORDER BY created_at DESC
        """, (current_ws,))
        rows = c.fetchall()
        conn.close()
        if rows:
            st.dataframe(pd.DataFrame(rows, columns=["id","title","type","status","created_at"]))
        else:
            st.caption("–ü–æ–∫–∞ –Ω–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –æ–ø–ª–∞—Ç.")

    # ---- RIGHT: expenses ----
    with right:
        st.markdown("### –†–∞—Å—Ö–æ–¥—ã (expenses)")
        exp_file = st.file_uploader("CSV —Å —Ä–∞—Å—Ö–æ–¥–∞–º–∏", type=["csv"], key="exp_upload")
        exp_gsheet = st.text_input("Google Sheets —Å —Ä–∞—Å—Ö–æ–¥–∞–º–∏ (–ø—É–±–ª–∏—á–Ω—ã–π)", key="exp_gsheet")

        if exp_file is not None:
            content = exp_file.read()
            try:
                df = pd.read_csv(io.BytesIO(content), sep=";")
                if df.shape[1] == 1:
                    df = pd.read_csv(io.BytesIO(content), sep=",")
            except Exception:
                df = pd.read_csv(io.BytesIO(content), sep=",")
            detected = list(df.columns)

            conn = get_conn()
            c = conn.cursor()
            ds_id = str(uuid.uuid4())
            now = datetime.utcnow().isoformat()
            c.execute("""INSERT INTO data_source
                (id, workspace_id, type, title, source_url, status, category, created_at, updated_at)
                VALUES (?,?,?,?,?,?,?,?,?)""",
                (ds_id, current_ws, "csv", exp_file.name, None, "uploaded", "expenses", now, now))
            up_id = str(uuid.uuid4())
            c.execute("""INSERT INTO data_upload
                (id, data_source_id, original_filename, storage_path, detected_schema, rows_count, created_at)
                VALUES (?,?,?,?,?,?,?)""",
                (up_id, ds_id, exp_file.name, "", ",".join(detected), len(df), now))
            conn.commit()
            conn.close()

            st.session_state.expenses_df = df
            st.session_state.expenses_ds_id = ds_id
            st.session_state.expenses_schema = detected

            st.success("–†–∞—Å—Ö–æ–¥—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É ¬´–ú–∞–ø–ø–∏–Ω–≥¬ª ‚Üí –ø—Ä–∞–≤—ã–π –±–ª–æ–∫.")
            st.dataframe(df.head())

        elif exp_gsheet:
            csv_url = parse_google_sheet_to_csv_url(exp_gsheet)
            if not csv_url:
                st.error("–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ Google Sheets")
            else:
                df = pd.read_csv(csv_url)
                detected = list(df.columns)

                conn = get_conn()
                c = conn.cursor()
                ds_id = str(uuid.uuid4())
                now = datetime.utcnow().isoformat()
                c.execute("""INSERT INTO data_source
                    (id, workspace_id, type, title, source_url, status, category, created_at, updated_at)
                    VALUES (?,?,?,?,?,?,?,?,?)""",
                    (ds_id, current_ws, "google_sheets", "Google Sheet (expenses)", exp_gsheet, "uploaded", "expenses", now, now))
                up_id = str(uuid.uuid4())
                c.execute("""INSERT INTO data_upload
                    (id, data_source_id, original_filename, storage_path, detected_schema, rows_count, created_at)
                    VALUES (?,?,?,?,?,?,?)""",
                    (up_id, ds_id, "sheet_expenses", "", ",".join(detected), len(df), now))
                conn.commit()
                conn.close()

                st.session_state.expenses_df = df
                st.session_state.expenses_ds_id = ds_id
                st.session_state.expenses_schema = detected

                st.success("–†–∞—Å—Ö–æ–¥—ã –∏–∑ Google Sheets –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
                st.dataframe(df.head())

        # —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö sources (expenses)
        st.markdown("#### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤")
        conn = get_conn()
        c = conn.cursor()
        c.execute("""
            SELECT id, title, type, status, created_at
            FROM data_source
            WHERE workspace_id = ? AND category = 'expenses'
            ORDER BY created_at DESC
        """, (current_ws,))
        rows = c.fetchall()
        conn.close()
        if rows:
            st.dataframe(pd.DataFrame(rows, columns=["id","title","type","status","created_at"]))
        else:
            st.caption("–ü–æ–∫–∞ –Ω–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ä–∞—Å—Ö–æ–¥–æ–≤.")

# ======== MAPPING ========
with tab_mapping:
    st.subheader("–ú–∞–ø–ø–∏–Ω–≥")
    col_left, col_right = st.columns(2)

    # ================== –û–ü–õ–ê–¢–´ ==================
    with col_left:
        st.markdown("### –ú–∞–ø–ø–∏–Ω–≥ –æ–ø–ª–∞—Ç")

        # –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –æ–ø–ª–∞—Ç
        conn = get_conn()
        c = conn.cursor()
        c.execute("""
            SELECT id, title, status, created_at
            FROM data_source
            WHERE workspace_id = ? AND category = 'orders'
            ORDER BY created_at DESC
        """, (current_ws,))
        order_sources = c.fetchall()
        conn.close()

        if not order_sources:
            st.info("–ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –æ–ø–ª–∞—Ç.")
        else:
            labels = [f"{r[1]} [{r[0][:6]}]" for r in order_sources]
            label = st.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ –æ–ø–ª–∞—Ç", labels, key="orders_src_sel")
            order_source_id = next(r[0] for i, r in enumerate(order_sources) if labels[i] == label)

            # —Å—Ö–µ–º–∞
            conn = get_conn()
            c = conn.cursor()
            c.execute("""
                SELECT detected_schema
                FROM data_upload
                WHERE data_source_id = ?
                ORDER BY created_at DESC
                LIMIT 1
            """, (order_source_id,))
            row = c.fetchone()
            conn.close()
            detected = row[0].split(",") if row and row[0] else []
            suggest = suggest_mapping(detected)

            # –ø—Ä–µ–≤—å—é
            orders_df_raw = None
            if st.session_state.orders_ds_id == order_source_id and st.session_state.orders_df is not None:
                orders_df_raw = st.session_state.orders_df.copy()
                st.caption("–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ñ–∞–π–ª–∞:")
                st.dataframe(orders_df_raw.head())
            else:
                st.caption("–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —Ä–∞–Ω–µ–µ ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ö–µ–º—É.")

            # ---- –§–û–†–ú–ê ----
            with st.form(f"orders_form_{order_source_id}"):
                # –≤–Ω—É—Ç—Ä–∏ —Ñ–æ—Ä–º—ã –æ–ø–ª–∞—Ç
                order_mapping = {}
                for f in suggest["orders"]:
                    tgt = f["target"]
                    wkey = f"ord_{order_source_id}_{tgt}"
                    options = ["‚Äî –Ω–µ –≤—ã–±—Ä–∞–Ω–æ ‚Äî"] + detected
                
                    if wkey in st.session_state:
                        # —É–∂–µ –±—ã–ª –≤—ã–±–æ—Ä ‚Äì –ù–ï–õ–¨–ó–Ø –¥–∞–≤–∞—Ç—å index
                        chosen = st.selectbox(
                            f'{f["label"]} ({tgt}) {"*" if f["required"] else ""}',
                            options=options,
                            key=wkey,
                        )
                    else:
                        # –ø–µ—Ä–≤—ã–π —Ä–∞–∑ ‚Äì –¥–∞—ë–º –ø–æ–¥—Å–∫–∞–∑–∫—É
                        sug = f.get("suggested_column")
                        idx = options.index(sug) if sug in detected else 0
                        chosen = st.selectbox(
                            f'{f["label"]} ({tgt}) {"*" if f["required"] else ""}',
                            options=options,
                            index=idx,
                            key=wkey,
                        )
                
                    order_mapping[tgt] = None if chosen == "‚Äî –Ω–µ –≤—ã–±—Ä–∞–Ω–æ ‚Äî" else chosen

                submitted = st.form_submit_button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–∞–ø–ø–∏–Ω–≥ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å ETL (–æ–ø–ª–∞—Ç—ã)")

                if submitted:
                    # –µ—Å–ª–∏ –≤ —Å–µ—Å—Å–∏–∏ –Ω–µ—Ç df ‚Äî –ø–æ–¥—Ç—è–Ω–µ–º –∏–∑ data_source
                    if orders_df_raw is None:
                        conn = get_conn()
                        c = conn.cursor()
                        c.execute("SELECT type, source_url, title FROM data_source WHERE id = ?", (order_source_id,))
                        ds_row = c.fetchone()
                        conn.close()
                
                        if ds_row and ds_row[0] == "google_sheets":
                            csv_url = parse_google_sheet_to_csv_url(ds_row[1]) or ds_row[1]
                            orders_df_raw = pd.read_csv(csv_url)
                        else:
                            st.error("–≠—Ç–æ—Ç CSV –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω —Ä–∞–Ω–µ–µ –∏ –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –Ω–∞ –¥–∏—Å–∫–µ. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –µ–≥–æ –∑–∞–Ω–æ–≤–æ –≤–æ –≤–∫–ª–∞–¥–∫–µ ¬´–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö¬ª.")
                            st.stop()
                    # –¥–∞–ª—å—à–µ –∫–∞–∫ –±—ã–ª–æ
                    conn = get_conn()
                    c = conn.cursor()
                    c.execute('DELETE FROM "order" WHERE data_source_id = ?', (order_source_id,))
                    conn.commit()
                    conn.close()
                
                    req = ["order_id", "order_date", "customer_name", "product", "revenue"]
                    miss = [x for x in req if not order_mapping.get(x)]
                    if miss:
                        st.error("–ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: " + ", ".join(miss))
                    else:
                        df_orders = apply_mapping_to_df(orders_df_raw, order_mapping, "orders")
                        insert_orders(df_orders, order_source_id)
                        rebuild_customers(current_ws)
                        m = calc_metrics(current_ws)
                        ins = generate_insights(m)

                        conn = get_conn()
                        c = conn.cursor()
                        snap_id = str(uuid.uuid4())
                        now = datetime.utcnow().isoformat()
                        c.execute("""
                            INSERT INTO metrics_snapshot
                            (id, workspace_id, period_from, period_to, payload_json, created_at)
                            VALUES (?,?,?,?,?,?)
                        """, (snap_id, current_ws, None, None, json.dumps({"metrics": m, "insights": ins}), now))
                        for txt in ins:
                            c.execute("""
                                INSERT INTO insight
                                (id, workspace_id, metrics_snapshot_id, text, rule_code, created_at)
                                VALUES (?,?,?,?,?,?)
                            """, (str(uuid.uuid4()), current_ws, snap_id, txt, "rule", now))
                        c.execute("UPDATE data_source SET status=?, updated_at=? WHERE id=?",
                                  ("processed", now, order_source_id))
                        conn.commit()
                        conn.close()
                        st.success("–û–ø–ª–∞—Ç—ã –ø—Ä–æ–º–∞–ø–ø–ª–µ–Ω—ã –∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã ‚úÖ")

    # ================== –†–ê–°–•–û–î–´ ==================
    with col_right:
        st.markdown("### –ú–∞–ø–ø–∏–Ω–≥ —Ä–∞—Å—Ö–æ–¥–æ–≤")

        conn = get_conn()
        c = conn.cursor()
        c.execute("""
            SELECT id, title, status, created_at
            FROM data_source
            WHERE workspace_id = ? AND category = 'expenses'
            ORDER BY created_at DESC
        """, (current_ws,))
        exp_sources = c.fetchall()
        conn.close()

        if not exp_sources:
            st.info("–ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ä–∞—Å—Ö–æ–¥–æ–≤.")
        else:
            labels = [f"{r[1]} [{r[0][:6]}]" for r in exp_sources]
            label = st.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ —Ä–∞—Å—Ö–æ–¥–æ–≤", labels, key="exp_src_sel")
            exp_source_id = next(r[0] for i, r in enumerate(exp_sources) if labels[i] == label)

            conn = get_conn()
            c = conn.cursor()
            c.execute("""
                SELECT detected_schema
                FROM data_upload
                WHERE data_source_id = ?
                ORDER BY created_at DESC
                LIMIT 1
            """, (exp_source_id,))
            row = c.fetchone()
            conn.close()
            detected = row[0].split(",") if row and row[0] else []
            suggest = suggest_mapping(detected)

            exp_df_raw = None
            if st.session_state.expenses_ds_id == exp_source_id and st.session_state.expenses_df is not None:
                exp_df_raw = st.session_state.expenses_df.copy()
                st.caption("–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ñ–∞–π–ª–∞:")
                st.dataframe(exp_df_raw.head())
            else:
                st.caption("–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —Ä–∞–Ω–µ–µ ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ö–µ–º—É.")

            # ---- –§–û–†–ú–ê ----
            with st.form(f"expenses_form_{exp_source_id}"):
                # –≤–Ω—É—Ç—Ä–∏ —Ñ–æ—Ä–º—ã —Ä–∞—Å—Ö–æ–¥–æ–≤
                expense_mapping = {}
                for f in suggest["expenses"]:
                    tgt = f["target"]
                    wkey = f"exp_{exp_source_id}_{tgt}"
                    options = ["‚Äî –Ω–µ –≤—ã–±—Ä–∞–Ω–æ ‚Äî"] + detected
                
                    if wkey in st.session_state:
                        chosen = st.selectbox(
                            f'{f["label"]} ({tgt}) {"*" if f["required"] else ""}',
                            options=options,
                            key=wkey,
                        )
                    else:
                        sug = f.get("suggested_column")
                        idx = options.index(sug) if sug in detected else 0
                        chosen = st.selectbox(
                            f'{f["label"]} ({tgt}) {"*" if f["required"] else ""}',
                            options=options,
                            index=idx,
                            key=wkey,
                        )
                
                    expense_mapping[tgt] = None if chosen == "‚Äî –Ω–µ –≤—ã–±—Ä–∞–Ω–æ ‚Äî" else chosen

                submitted_exp = st.form_submit_button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–∞–ø–ø–∏–Ω–≥ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å ETL (—Ä–∞—Å—Ö–æ–¥—ã)")

                if submitted_exp:
                    if exp_df_raw is None:
                        conn = get_conn()
                        c = conn.cursor()
                        c.execute("SELECT type, source_url, title FROM data_source WHERE id = ?", (exp_source_id,))
                        ds_row = c.fetchone()
                        conn.close()
                
                        if ds_row and ds_row[0] == "google_sheets":
                            csv_url = parse_google_sheet_to_csv_url(ds_row[1]) or ds_row[1]
                            exp_df_raw = pd.read_csv(csv_url)
                        else:
                            st.error("–≠—Ç–æ—Ç CSV —Å —Ä–∞—Å—Ö–æ–¥–∞–º–∏ –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –µ–≥–æ –∑–∞–Ω–æ–≤–æ –≤–æ –≤–∫–ª–∞–¥–∫–µ ¬´–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö¬ª.")
                            st.stop()
                    # –¥–∞–ª—å—à–µ –∫–∞–∫ –±—ã–ª–æ
                    conn = get_conn()
                    c = conn.cursor()
                    c.execute("DELETE FROM expense WHERE data_source_id = ?", (exp_source_id,))
                    conn.commit()
                    conn.close()
                
                    req = ["expense_date", "category", "amount"]
                    miss = [x for x in req if not expense_mapping.get(x)]
                    if miss:
                        st.error("–ù–µ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: " + ", ".join(miss))
                    else:
                        df_exp = apply_mapping_to_df(exp_df_raw, expense_mapping, "expenses")
                        insert_expenses(df_exp, exp_source_id)
                        rebuild_customers(current_ws)
                        m = calc_metrics(current_ws)
                        ins = generate_insights(m)

                        conn = get_conn()
                        c = conn.cursor()
                        snap_id = str(uuid.uuid4())
                        now = datetime.utcnow().isoformat()
                        c.execute("""
                            INSERT INTO metrics_snapshot
                            (id, workspace_id, period_from, period_to, payload_json, created_at)
                            VALUES (?,?,?,?,?,?)
                        """, (snap_id, current_ws, None, None, json.dumps({"metrics": m, "insights": ins}), now))
                        for txt in ins:
                            c.execute("""
                                INSERT INTO insight
                                (id, workspace_id, metrics_snapshot_id, text, rule_code, created_at)
                                VALUES (?,?,?,?,?,?)
                            """, (str(uuid.uuid4()), current_ws, snap_id, txt, "rule", now))
                        c.execute("UPDATE data_source SET status=?, updated_at=? WHERE id=?",
                                  ("processed", now, exp_source_id))
                        conn.commit()
                        conn.close()
                        st.success("–†–∞—Å—Ö–æ–¥—ã –ø—Ä–æ–º–∞–ø–ø–ª–µ–Ω—ã –∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã ‚úÖ")
